{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYiZq0X2oB5t"
   },
   "source": [
    "# **CSCE 5218 / CSCE 4930 Deep Learning**\n",
    "\n",
    "# **HW1a The Perceptron** (20 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGVmKzgG2Ium",
    "outputId": "884f14ac-4ebe-45b6-c3a6-2c659e03c068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-04 16:31:03--  http://www.cse.unt.edu/~blanco/csce5218/hw1a/train.dat\n",
      "Resolving www.cse.unt.edu (www.cse.unt.edu)... 129.120.151.91\n",
      "Connecting to www.cse.unt.edu (www.cse.unt.edu)|129.120.151.91|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11244 (11K) [application/x-ns-proxy-autoconfig]\n",
      "Saving to: ‘train.dat’\n",
      "\n",
      "train.dat           100%[===================>]  10.98K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-02-04 16:31:03 (305 MB/s) - ‘train.dat’ saved [11244/11244]\n",
      "\n",
      "--2021-02-04 16:31:03--  http://www.cse.unt.edu/~blanco/csce5218/hw1a/test.dat\n",
      "Resolving www.cse.unt.edu (www.cse.unt.edu)... 129.120.151.91\n",
      "Connecting to www.cse.unt.edu (www.cse.unt.edu)|129.120.151.91|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2844 (2.8K) [application/x-ns-proxy-autoconfig]\n",
      "Saving to: ‘test.dat’\n",
      "\n",
      "test.dat            100%[===================>]   2.78K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-02-04 16:31:03 (479 MB/s) - ‘test.dat’ saved [2844/2844]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "!wget http://www.cse.unt.edu/~blanco/csce5218/hw1a/train.dat\n",
    "!wget http://www.cse.unt.edu/~blanco/csce5218/hw1a/test.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A69DxPSc8vNs",
    "outputId": "eccfcef8-1a31-4947-94c3-b73f5673cc88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\t\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t0\t1\t0\n",
      "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\n"
     ]
    }
   ],
   "source": [
    "# Take a peek at the datasets\n",
    "!head train.dat\n",
    "!head test.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cXAsP_lw3QwJ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "\n",
    "# Corpus reader, all columns but the last one are coordinates;\n",
    "#   the last column is the label\n",
    "def read_data(file_name):\n",
    "    f = open(file_name, 'r')\n",
    "\n",
    "    data = []\n",
    "    # Discard header line\n",
    "    f.readline()\n",
    "    for instance in f.readlines():\n",
    "        if not re.search('\\t', instance): continue\n",
    "        instance = list(map(int, instance.strip().split('\\t')))\n",
    "        # Add a dummy input so that w0 becomes the bias\n",
    "        instance = [-1] + instance\n",
    "        data += [instance]\n",
    "    return data\n",
    "\n",
    "\n",
    "def dot_product(array1, array2):\n",
    "    # You do not to write code like this, but get used to it\n",
    "    return sum([w * x for w, x in zip(array1, array2)])\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "# Accuracy = percent of correct predictions\n",
    "def get_accuracy(weights, instances):\n",
    "    # You do not to write code like this, but get used to it\n",
    "    correct = sum([1 if predict(weights, instance) == instance[-1] else 0\n",
    "                   for instance in instances])\n",
    "    return correct * 100 / len(instances)\n",
    "\n",
    "\n",
    "# Predict a new instance; this is the definition of the perceptron\n",
    "def predict(weights, instance):\n",
    "    if sigmoid(dot_product(weights, instance)) >= 0.5:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Train a perceptron with instances\n",
    "#   and hyperparameters lr (leearning rate) and epochs\n",
    "# The implementation comes from the definition of the perceptron\n",
    "# Training consists on fitting the parameters\n",
    "#   The parameters are the weights, that's the only thing training is responsible to fit\n",
    "#     (recall that w0 is the bias, and w1..wn are the weights for each coordinate)\n",
    "#   Hyperparameters (lr and epochs) are given to the training algorithm\n",
    "# We are updating weights in the opposite direction of the gradient of the error,\n",
    "#   so with a \"decent\" lr we are guaranteed to reduce the error after each iteration.\n",
    "def train_perceptron(instances, lr, epochs):\n",
    "    weights = [0] * (len(instances[0])-1)\n",
    "    # weights = [0, 0, 0, ...,  0]\n",
    "\n",
    "    while epochs > 0:\n",
    "        for instance in instances:\n",
    "            in_value = dot_product(weights, instance)\n",
    "            output = sigmoid(in_value)\n",
    "            error = instance[-1] - output\n",
    "            for i in range(0, len(weights)):\n",
    "                weights[i] += lr * error * output * (1-output) * instance[i]\n",
    "\n",
    "        epochs -= 1\n",
    "        if epochs == 0:\n",
    "            break\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50YvUza-BYQF",
    "outputId": "281fefc6-1453-42b9-ae43-d1e7684d487a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n"
     ]
    }
   ],
   "source": [
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "lr = 0.005\n",
    "epochs = 5\n",
    "weights = train_perceptron(instances_tr, lr, epochs)\n",
    "accuracy = get_accuracy(weights, instances_te)\n",
    "print(f\"#tr: {len(instances_tr):3}, epochs: {epochs:3}, learning rate: {lr:.3f}; \"\n",
    "      f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBXkvaiQMohX"
   },
   "source": [
    "## Questions\n",
    "\n",
    "Answer the following questions. Include your implementation and the output for each question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCQ6BEk1CBlr"
   },
   "source": [
    "\n",
    "\n",
    "### Question 1\n",
    "\n",
    "In `train_perceptron(instances, lr, epochs)`, we have the follosing code:\n",
    "```\n",
    "in_value = dot_product(weights, instance)\n",
    "output = sigmoid(in_value)\n",
    "error = instance[-1] - output\n",
    "```\n",
    "\n",
    "Why don't we have the following code snippet instead?\n",
    "```\n",
    "output = predict(weights, instance)\n",
    "error = instance[-1] - output\n",
    "```\n",
    "\n",
    "#### TODO Add your answer here (text only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU3c3m6YL2rK"
   },
   "source": [
    "### Question 2\n",
    "Train the perceptron with the following hyperparameters and calculate the accuracy with the test dataset.\n",
    "\n",
    "```\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
    "num_epochs = [5, 10, 20, 50, 100]              # number of epochs\n",
    "lr = [0.005, 0.01, 0.05]              # learning rate\n",
    "```\n",
    "\n",
    "TODO Write your code below and include the output of your code.\n",
    "The output should look like the following:\n",
    "```\n",
    "# tr:  20, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "# tr:  20, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "# tr:  20, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "[and so on for all the combinations]\n",
    "```\n",
    "You will get different results with differet hyperparameters.\n",
    "\n",
    "#### TODO Add your answer here (code and output in the format above) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhjaRFjq4nEw",
    "outputId": "e6838456-fc65-454c-a532-aee7454d8d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tr:  20, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
      "#tr:  20, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  20, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 62.0\n",
      "#tr:  40, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
      "#tr:  40, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr:  40, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 100, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 72.0\n",
      "#tr: 100, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 100, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 75.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 200, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 200, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
      "#tr: 200, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 200, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 67.0\n",
      "#tr: 200, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 73.0\n",
      "#tr: 200, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 75.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 300, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 300, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
      "#tr: 300, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 300, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 79.0\n",
      "#tr: 300, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 300, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 76.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 81.0\n",
      "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 70.0\n",
      "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
      "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 72.0\n",
      "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "tr_percent = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "num_epochs = [5, 10, 20, 50, 100]\n",
    "lrt = [0.005, 0.01, 0.05]\n",
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "\n",
    "for per in tr_percent:\n",
    "  for epochs in num_epochs:\n",
    "    for lr in lrt:\n",
    "      var = int(len(instances_tr)*per)\n",
    "    instances_tr2 = random.sample(instances_tr, var)\n",
    "      #instances_tr2 = random.sample(instances_tr, var)\n",
    "      weights = train_perceptron(instances_tr2, lr, epochs)\n",
    "      accuracy = get_accuracy(weights, instances_te)\n",
    "      print(f\"#tr: {len(instances_tr2):3}, epochs: {epochs:3}, learning rate: {lr:.3f}; \"f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFB9MtwML24O"
   },
   "source": [
    "### Question 3\n",
    "Write a couple paragraphs interpreting the results with all the combinations of hyperparameters. Drawing a plot will probably help you make a point. In particular, answer the following:\n",
    "- Do you need to train with all the training dataset to get the highest accuracy with the test dataset?\n",
    "- How do you justify that training the second run obtains worse accuracy than the first one (despite the second one uses more training data)?\n",
    "   ```\n",
    "#tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
    "#tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "```\n",
    "- Can you get higher accuracy with additional hyperparameters (higher than `80.0`)?\n",
    "- Is it always worth training for more epochs (while keeping all other hyperparameters fixed)?\n",
    "\n",
    "#### TODO Add your answer here (code and text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of HW1a - The Perceptron",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
